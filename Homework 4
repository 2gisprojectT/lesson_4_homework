1.	Защита 1 уровня «что-то потестируем» не работает, потому что, во-первых, мы не преследуем в таком случае цели создания целостного набора тест-кейсов, во-вторых, каждый человек обладает индивидуальным мышлением, в следствие чего он предвзято относится к функционалу, с которым в данный момент работает, что приводит, опять же, к отсутствию полноты тест-кейсов, и, в-третьих, функционал обрабатывается не полностью, что может привести к ухудшению качества продукта.
2.	Написание большого количества тестов не помогает, во-первых, потому что на это необходимо больше ресурсов (в основном человеческих), а, во-вторых, тестировщики пропускают менее критические ошибки. А наличие ошибок (любых) всегда приводит к ухудшению качества.
3.	Анализ позволяет, во-первых, глобально оценить продукт, над которым мы работаем, в следствие чего можно качественно оценить риски, с которыми можем столкнуться мы в процессе тестирования, чтобы не пустить баги в релиз. Во-вторых, значительно увеличиваем адаптивность тестов и сокращаем их количество, то есть с функциональной точки зрения уменьшаем затраты по времени на проведение тестирования, при этом не ухудшая покрытия.
4.	Для проектирования хорошей защиты от багов нужно:
Проанализировать продукт, найти возможные уязвимости.
Определиться с объемом тестов (влияет ограниченность во времени, интеллектуальные ресурсы).
Учесть потребности пользователя.
Спроектировать программу тестирования, то есть какие тесты нужны и каким образом они будут выполняться.
5.	На выходе анализа должны быть:
Карта функционала (например, MIndMap).
Что с чем важно тестировать (определиться с функциональными, модульными взаимосвязями).
Что важнее всего? (Расставить по приоритету функционал нашего продукта, чтобы протестировать главные компоненты в первую очередь).
Определиться в соответствие с предыдущем пунктом с видами тестирования.
Какие условия и окружения важнее всего?
Что чаще всего ломается (уязвимости продукта).
Слабости продукта относительно предпочтений пользователя, а также функционал, который в первую очередь необходим пользователю.
6.	Приоритеты нужно расставлять, потому что при неработоспособности определенных компонент продукта можно потерять колоссальное количество потенциально заработанных денежных средств. Приоритет функциональности зависит, во-первых, от назначения программного продукта, во-вторых, от предпочтений пользователя. 
7.	Внешними факторами являются:
Длительность итераций, так как этот фактор напрямую зависим от периода между релизами (он должен быть гораздо меньше, чтобы успевать протестировать новую версию продукта).
Регулярность публичных релизов  - распланировать программу тестирования на конкретный период.
Ограничения по времени, по ресурсам – наиболее подробно и качественно протестировать продукт за конкретный пириод времени.
Допустимость, недопустимость ошибок – с какими можно выпускать продукт в релиз, с какими нельзя (если на исправление нет времени).
Возможность автоматизации.
8.	Разные комплекты тестов необходимы для приоритезации тестов, так как необходимо оценивать обстановку на данный момент (сколько времени на тестирование есть, какое количество ресурсов доступно). Прогонять нужно для каждого комплекта по-разному.
BVT (Build Verification Test) – самый поверхностный вид тестирования, наиболее часто повторяющийся, чаще всего автоматизируемый. Проводится с целью быстрой оценки качества ПО, нахождения критических ошибок, и оценки стабильности продукта.
UAT (User Acceptanse Test) – вид тестирования, направленный, в первую очередь, на проверки возможности выпуска продукта в релиз, так как данный вид тестирования проверяет продукт на возможность успешного использования его пользователем. Проводится непосредственно перед релизом (в каждой сборке). Но с запасом по времени.
FTP (Full Test Path) – полный набор тестов, предназначенный для масштабной проверки качества программного обеспечения. Проводится на протяжении «жизни» программного продукта, так как за один раз (период времени) провести его невозможно (количество тестов огромное). Тесты обязательно структурированы, приоритезированы.
9.	Если пропустили баг нужно заново проанализировать продукт по нескольким критериям:
Почему пропустили?
Насколько критично? (чтобы найти приоритет исправления бага)
Какой из наборов тестов расширять? (Чтобы не допустить в последствие аналогичных багов)
Что еще нужно учитывать?


